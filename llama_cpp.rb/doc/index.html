<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>
  File: README
  
    &mdash; Documentation by YARD 0.9.37
  
</title>

  <link rel="stylesheet" href="css/style.css" type="text/css" />

  <link rel="stylesheet" href="css/common.css" type="text/css" />

<script type="text/javascript">
  pathId = "README";
  relpath = '';
</script>


  <script type="text/javascript" charset="utf-8" src="js/app.js"></script>


  </head>
  <body>
    <div class="nav_wrap">
      <iframe id="nav" src="class_list.html?1"></iframe>
      <div id="resizer"></div>
    </div>

    <div id="main" tabindex="-1">
      <div id="header">
        <div id="menu">
  
    <a href="_index.html">Index</a> &raquo; 
    <span class="title">File: README</span>
  
</div>

        <div id="search">
  
    <a class="full_list_link" id="class_list_link"
        href="class_list.html">

        <svg width="24" height="24">
          <rect x="0" y="4" width="24" height="4" rx="1" ry="1"></rect>
          <rect x="0" y="12" width="24" height="4" rx="1" ry="1"></rect>
          <rect x="0" y="20" width="24" height="4" rx="1" ry="1"></rect>
        </svg>
    </a>
  
</div>
        <div class="clear"></div>
      </div>

      <div id="content"><div id='filecontents'>
<h1 id="label-llama_cpp.rb">llama_cpp.rb</h1>

<p><a href="https://badge.fury.io/rb/llama_cpp"><img src="https://badge.fury.io/rb/llama_cpp.svg"></a> <a href="https://github.com/yoshoku/llama_cpp.rb/blob/main/LICENSE.txt"><img src="https://img.shields.io/badge/License-MIT-yellowgreen.svg"></a> <a href="https://yoshoku.github.io/llama_cpp.rb/doc/"><img src="https://img.shields.io/badge/api-reference-blue.svg"></a></p>

<p>llama_cpp.rb provides Ruby bindings for the <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a>.</p>

<p>This gem is still under development and may undergo many changes in the future.</p>

<h2 id="label-Installation">Installation</h2>

<p>Install the llama.cpp. If you use homebrew, install it by executing:</p>

<pre class="code ruby"><code class="ruby">$ brew install llama.cpp
</code></pre>

<p>Install the gem and add to the application’s Gemfile by executing:</p>

<pre class="code ruby"><code class="ruby">$ bundle config --local build.llama_cpp &quot;--with-opt-dir=/opt/homebrew/&quot;
$ bundle add llama_cpp
</code></pre>

<p>If bundler is not being used to manage dependencies, install the gem by executing:</p>

<pre class="code ruby"><code class="ruby">$ gem install llama_cpp -- --with-opt-dir=/opt/homebrew
</code></pre>

<h2 id="label-Usage">Usage</h2>

<p>Prepare the quantized model by refering to <a href="https://github.com/ggerganov/llama.cpp#usage">the usage section on the llama.cpp README</a>. For example, you could prepare the quatization model based on <a href="https://huggingface.co/openlm-research/open_llama_7b">open_llama_7b</a> or more useful in the context of Ruby might be a smaller model such as <a href="https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0">tiny_llama_1b</a>:</p>

<pre class="code ruby"><code class="ruby">$ cd ~/
$ brew install git-lfs
$ git lfs install
$ git clone https://github.com/ggerganov/llama.cpp.git
$ cd llama.cpp
$ python3 -m pip install -r requirements.txt
$ cd models
$ git clone https://huggingface.co/openlm-research/open_llama_7b
$ cd ../
$ python3 convert-hf-to-gguf.py models/open_llama_7b
$ make
$ ./llama-quantize ./models/open_llama_7b/ggml-model-f16.gguf ./models/open_llama_7b/ggml-model-q4_0.bin q4_0
</code></pre>

<p>An example of Ruby code that generates sentences with the quantization model is as follows:</p>

<pre class="code ruby"><code class="ruby"><span class='id identifier rubyid_require'>require</span> <span class='tstring'><span class='tstring_beg'>&#39;</span><span class='tstring_content'>llama_cpp</span><span class='tstring_end'>&#39;</span></span>

<span class='const'><span class='object_link'><a href="LlamaCpp.html" title="LlamaCpp (module)">LlamaCpp</a></span></span><span class='period'>.</span><span class='id identifier rubyid_ggml_backend_load_all'><span class='object_link'><a href="LlamaCpp.html#ggml_backend_load_all-class_method" title="LlamaCpp.ggml_backend_load_all (method)">ggml_backend_load_all</a></span></span>

<span class='id identifier rubyid_model_params'>model_params</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="LlamaCpp.html" title="LlamaCpp (module)">LlamaCpp</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="LlamaCpp/LlamaModelParams.html" title="LlamaCpp::LlamaModelParams (class)">LlamaModelParams</a></span></span><span class='period'>.</span><span class='id identifier rubyid_new'>new</span>
<span class='id identifier rubyid_model'>model</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="LlamaCpp.html" title="LlamaCpp (module)">LlamaCpp</a></span></span><span class='op'>::</span><span class='id identifier rubyid_llama_model_load_from_file'><span class='object_link'><a href="LlamaCpp.html#llama_model_load_from_file-class_method" title="LlamaCpp.llama_model_load_from_file (method)">llama_model_load_from_file</a></span></span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&#39;</span><span class='tstring_content'>/home/user/llama.cpp/models/open_llama_7b/ggml-model-q4_0.bin</span><span class='tstring_end'>&#39;</span></span><span class='comma'>,</span> <span class='id identifier rubyid_model_params'>model_params</span><span class='rparen'>)</span>

<span class='id identifier rubyid_context_params'>context_params</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="LlamaCpp.html" title="LlamaCpp (module)">LlamaCpp</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="LlamaCpp/LlamaContextParams.html" title="LlamaCpp::LlamaContextParams (class)">LlamaContextParams</a></span></span><span class='period'>.</span><span class='id identifier rubyid_new'>new</span>
<span class='id identifier rubyid_context'>context</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="LlamaCpp.html" title="LlamaCpp (module)">LlamaCpp</a></span></span><span class='period'>.</span><span class='id identifier rubyid_llama_init_from_model'><span class='object_link'><a href="LlamaCpp.html#llama_init_from_model-class_method" title="LlamaCpp.llama_init_from_model (method)">llama_init_from_model</a></span></span><span class='lparen'>(</span><span class='id identifier rubyid_model'>model</span><span class='comma'>,</span> <span class='id identifier rubyid_context_params'>context_params</span><span class='rparen'>)</span>

<span class='id identifier rubyid_puts'>puts</span> <span class='const'><span class='object_link'><a href="top-level-namespace.html#LLaMACpp-constant" title="LLaMACpp (constant)">LLaMACpp</a></span></span><span class='period'>.</span><span class='id identifier rubyid_generate'>generate</span><span class='lparen'>(</span><span class='id identifier rubyid_context'>context</span><span class='comma'>,</span> <span class='tstring'><span class='tstring_beg'>&#39;</span><span class='tstring_content'>Hello, World.</span><span class='tstring_end'>&#39;</span></span><span class='rparen'>)</span>

<span class='const'><span class='object_link'><a href="LlamaCpp.html" title="LlamaCpp (module)">LlamaCpp</a></span></span><span class='period'>.</span><span class='id identifier rubyid_llama_free'><span class='object_link'><a href="LlamaCpp.html#llama_free-class_method" title="LlamaCpp.llama_free (method)">llama_free</a></span></span><span class='lparen'>(</span><span class='id identifier rubyid_context'>context</span><span class='rparen'>)</span>
<span class='const'><span class='object_link'><a href="LlamaCpp.html" title="LlamaCpp (module)">LlamaCpp</a></span></span><span class='period'>.</span><span class='id identifier rubyid_llama_model_free'><span class='object_link'><a href="LlamaCpp.html#llama_model_free-class_method" title="LlamaCpp.llama_model_free (method)">llama_model_free</a></span></span><span class='lparen'>(</span><span class='id identifier rubyid_model'>model</span><span class='rparen'>)</span>
</code></pre>

<h2 id="label-Contributing">Contributing</h2>

<p>Bug reports and pull requests are welcome on GitHub at <a href="https://github.com/yoshoku/llama_cpp.rb">github.com/yoshoku/llama_cpp.rb</a>. This project is intended to be a safe, welcoming space for collaboration, and contributors are expected to adhere to the <a href="https://github.com/yohsoku/llama_cpp.rb/blob/main/CODE_OF_CONDUCT.md">code of conduct</a>.</p>

<h2 id="label-License">License</h2>

<p>The gem is available as open source under the terms of the <a href="https://opensource.org/licenses/MIT">MIT License</a>.</p>

<h2 id="label-Code+of+Conduct">Code of Conduct</h2>

<p>Everyone interacting in the LlamaCpp project’s codebases, issue trackers, chat rooms and mailing lists is expected to follow the <a href="https://github.com/yoshoku/llama_cpp.rb/blob/main/CODE_OF_CONDUCT.md">code of conduct</a>.</p>
</div></div>

      <div id="footer">
  Generated on Sun Feb  2 15:37:57 2025 by
  <a href="https://yardoc.org" title="Yay! A Ruby Documentation Tool" target="_parent">yard</a>
  0.9.37 (ruby-3.4.1).
</div>

    </div>
  </body>
</html>